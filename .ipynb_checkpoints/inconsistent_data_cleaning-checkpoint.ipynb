{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308bacbc",
   "metadata": {},
   "source": [
    "## Get our environment set up\n",
    "The first thing we'll need to do is load in the libraries and dataset we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0793f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helpful modules\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import chardet\n",
    "\n",
    "# read in all our data\n",
    "professors = pd.read_csv(\"../input/pakistan-intellectual-capital/pakistan_intellectual_capital.csv\")\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c9857",
   "metadata": {},
   "source": [
    "Add Some more packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bf75f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a4624",
   "metadata": {},
   "source": [
    "### Do some preliminary text pre-processing\n",
    "We'll begin by taking a quick look at the first few rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53723ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S#</th>\n",
       "      <th>Teacher Name</th>\n",
       "      <th>University Currently Teaching</th>\n",
       "      <th>Department</th>\n",
       "      <th>Province University Located</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Terminal Degree</th>\n",
       "      <th>Graduated from</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Area of Specialization/Research Interests</th>\n",
       "      <th>Other Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Dr. Abdul Basit</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Engineering &amp; DBMS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Dr. Waheed Noor</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DBMS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Dr. Junaid Baber</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information processing, Multimedia mining</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Dr. Maheen Bakhtyar</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NLP, Information Retrieval, Question Answering...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>Samina Azim</td>\n",
       "      <td>Sardar Bahadur Khan Women's University</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Lecturer</td>\n",
       "      <td>BS</td>\n",
       "      <td>Balochistan University of Information Technolo...</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>VLSI Electronics DLD Database</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  S#         Teacher Name  \\\n",
       "0           2   3      Dr. Abdul Basit   \n",
       "1           4   5      Dr. Waheed Noor   \n",
       "2           5   6     Dr. Junaid Baber   \n",
       "3           6   7  Dr. Maheen Bakhtyar   \n",
       "4          24  25          Samina Azim   \n",
       "\n",
       "            University Currently Teaching             Department  \\\n",
       "0               University of Balochistan  Computer Science & IT   \n",
       "1               University of Balochistan  Computer Science & IT   \n",
       "2               University of Balochistan  Computer Science & IT   \n",
       "3               University of Balochistan  Computer Science & IT   \n",
       "4  Sardar Bahadur Khan Women's University       Computer Science   \n",
       "\n",
       "  Province University Located          Designation Terminal Degree  \\\n",
       "0                 Balochistan  Assistant Professor             PhD   \n",
       "1                 Balochistan  Assistant Professor             PhD   \n",
       "2                 Balochistan  Assistant Professor             PhD   \n",
       "3                 Balochistan  Assistant Professor             PhD   \n",
       "4                 Balochistan             Lecturer              BS   \n",
       "\n",
       "                                      Graduated from   Country    Year  \\\n",
       "0                      Asian Institute of Technology  Thailand     NaN   \n",
       "1                      Asian Institute of Technology  Thailand     NaN   \n",
       "2                      Asian Institute of Technology  Thailand     NaN   \n",
       "3                      Asian Institute of Technology  Thailand     NaN   \n",
       "4  Balochistan University of Information Technolo...  Pakistan  2005.0   \n",
       "\n",
       "           Area of Specialization/Research Interests Other Information  \n",
       "0                        Software Engineering & DBMS               NaN  \n",
       "1                                               DBMS               NaN  \n",
       "2          Information processing, Multimedia mining               NaN  \n",
       "3  NLP, Information Retrieval, Question Answering...               NaN  \n",
       "4                      VLSI Electronics DLD Database               NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professors.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac6c10",
   "metadata": {},
   "source": [
    "Say we're interested in cleaning up the \"Country\" column to make sure there's no data entry inconsistencies in it. We could go through and check each row by hand, of course, and hand-correct inconsistencies when we find them. There's a more efficient way to do this, though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63cad8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Germany', ' New Zealand', ' Sweden', ' USA', 'Australia',\n",
       "       'Austria', 'Canada', 'China', 'Finland', 'France', 'Greece',\n",
       "       'HongKong', 'Ireland', 'Italy', 'Japan', 'Macau', 'Malaysia',\n",
       "       'Mauritius', 'Netherland', 'New Zealand', 'Norway', 'Pakistan',\n",
       "       'Portugal', 'Russian Federation', 'Saudi Arabia', 'Scotland',\n",
       "       'Singapore', 'South Korea', 'SouthKorea', 'Spain', 'Sweden',\n",
       "       'Thailand', 'Turkey', 'UK', 'USA', 'USofA', 'Urbana', 'germany'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'Country' column\n",
    "countries = professors['Country'].unique()\n",
    "\n",
    "sorted_countries = countries.copy()\n",
    "sorted_countries.sort()\n",
    "sorted_countries  # those starting with blanks are first\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "countries.sort()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db286fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listing(x):\n",
    "    countries = professors[x].unique()\n",
    "    countries.sort()\n",
    "    letters = 'abcdefghijklmnopqrstuvxyz'\n",
    "    for l in letters:\n",
    "        t = [x for x in countries if re.search('^\\s*'+l, x, re.I)]\n",
    "        if t: print(t)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f301638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Australia', 'Austria']\n",
      "['Canada', 'China']\n",
      "['Finland', 'France']\n",
      "[' Germany', 'Greece', 'germany']\n",
      "['HongKong']\n",
      "['Ireland', 'Italy']\n",
      "['Japan']\n",
      "['Macau', 'Malaysia', 'Mauritius']\n",
      "[' New Zealand', 'Netherland', 'New Zealand', 'Norway']\n",
      "['Pakistan', 'Portugal']\n",
      "['Russian Federation']\n",
      "[' Sweden', 'Saudi Arabia', 'Scotland', 'Singapore', 'South Korea', 'SouthKorea', 'Spain', 'Sweden']\n",
      "['Thailand', 'Turkey']\n",
      "[' USA', 'UK', 'USA', 'USofA', 'Urbana']\n"
     ]
    }
   ],
   "source": [
    "listing('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c64b08",
   "metadata": {},
   "source": [
    "Just looking at this, I can see some problems due to inconsistent data entry: ' Germany', and 'germany', for example, or ' New Zealand' and 'New Zealand'.\n",
    "\n",
    "The first thing I'm going to do is make everything lower case (I can change it back at the end if I like) and remove any white spaces at the beginning and end of cells. Inconsistencies in capitalizations and trailing white spaces are very common in text data and you can fix a good 80% of your text data entry inconsistencies by doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9a58f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "professors['Country'] = professors['Country'].str.lower()\n",
    "# remove [leading &] trailing white spaces\n",
    "professors['Country'] = professors['Country'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51dfc7a",
   "metadata": {},
   "source": [
    "It does look like there is another inconsistency: 'southkorea' and 'south korea' should be the same.\n",
    "\n",
    "We're going to use the [fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy) package to help identify which strings are closest to each other. This dataset is small enough that we could probably could correct errors by hand, but that approach doesn't scale well. (Would you want to correct a thousand errors by hand? What about ten thousand? Automating things as early as possible is generally a good idea. Plus, itâ€™s fun!)\n",
    "\n",
    ">Fuzzy matching: The process of automatically finding text strings that are very similar to the target string. In general, a string is considered \"closer\" to another one the fewer characters you'd need to change if you were transforming one string into another. So \"apple\" and \"snapple\" are two changes away from each other (add \"s\" and \"n\") while \"in\" and \"on\" and one change away (rplace \"i\" with \"o\"). You won't always be able to rely on fuzzy matching 100%, but it will usually end up saving you at least a little time.\n",
    "\n",
    "Fuzzywuzzy returns a ratio given two strings. The closer the ratio is to 100, the smaller the edit distance between the two strings. Here, we're going to get the ten strings from our list of cities that have the closest distance to \"south korea\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9307801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('South Korea', 100),\n",
       " ('SouthKorea', 48),\n",
       " ('Saudi Arabia', 43),\n",
       " ('Norway', 35),\n",
       " ('Austria', 33),\n",
       " ('Ireland', 33),\n",
       " ('Pakistan', 32),\n",
       " ('Portugal', 32),\n",
       " ('Scotland', 32),\n",
       " ('Australia', 30)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top 10 closest matches to \"south korea\"\n",
    "matches = fuzzywuzzy.process.extract(\"south korea\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "# take a look at them\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16972dc2",
   "metadata": {},
   "source": [
    "We can see that two of the items in the cities are very close to \"south korea\": \"south korea\" and \"southkorea\". Let's replace all rows in our \"Country\" column that have a ratio of > 47 with \"south korea\".\n",
    "\n",
    "To do this, I'm going to write a function. (It's a good idea to write a general purpose function you can reuse if you think you might have to do a specific task more than once or twice. This keeps you from having to copy and paste code too often, which saves time and can help prevent mistakes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ecade5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to replace rows in the provided column of the provided dataframe\n",
    "# that match the provided string above the provided ratio with the provided string\n",
    "def replace_matches_in_column(df, column, string_to_match, min_ratio = 47):\n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    # get the top 10 closest matches to our input string\n",
    "    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n",
    "                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "    # only get matches with a ratio > 90\n",
    "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
    "\n",
    "    # get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match\n",
    "    \n",
    "    # let us know the function's done\n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7053a53",
   "metadata": {},
   "source": [
    "Now that we have a function, we can put it to the test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "342ad3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# use the function we just wrote to replace close matches to \"south korea\" with \"south korea\"\n",
    "replace_matches_in_column(df=professors, column='Country', string_to_match=\"south korea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166877f",
   "metadata": {},
   "source": [
    "And now let's check the unique values in our \"Country\" column again and make sure we've tidied up \"south korea\" correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f991bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['australia', 'austria']\n",
      "['canada', 'china']\n",
      "['finland', 'france']\n",
      "['germany', 'greece']\n",
      "['hongkong']\n",
      "['ireland', 'italy']\n",
      "['japan']\n",
      "['macau', 'malaysia', 'mauritius']\n",
      "['netherland', 'new zealand', 'norway']\n",
      "['pakistan', 'portugal']\n",
      "['russian federation']\n",
      "['saudi arabia', 'scotland', 'singapore', 'south korea', 'spain', 'sweden']\n",
      "['thailand', 'turkey']\n",
      "['uk', 'urbana', 'usa', 'usofa']\n"
     ]
    }
   ],
   "source": [
    "listing('Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c55f264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' USA', 100),\n",
       " ('USA', 100),\n",
       " ('USofA', 75),\n",
       " ('Austria', 60),\n",
       " ('Australia', 50),\n",
       " ('Spain', 50),\n",
       " ('Urbana', 44),\n",
       " ('UK', 40),\n",
       " ('Malaysia', 36),\n",
       " ('Pakistan', 36)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzywuzzy.process.extract(\"usa\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "414cb6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "replace_matches_in_column(df=professors, column='Country', string_to_match=\"usa\", min_ratio=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "166078e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['australia', 'austria']\n",
      "['canada', 'china']\n",
      "['finland', 'france']\n",
      "['germany', 'greece']\n",
      "['hongkong']\n",
      "['ireland', 'italy']\n",
      "['japan']\n",
      "['macau', 'malaysia', 'mauritius']\n",
      "['netherland', 'new zealand', 'norway']\n",
      "['pakistan', 'portugal']\n",
      "['russian federation']\n",
      "['saudi arabia', 'scotland', 'singapore', 'south korea', 'spain', 'sweden']\n",
      "['thailand', 'turkey']\n",
      "['uk', 'urbana', 'usa']\n"
     ]
    }
   ],
   "source": [
    "listing('Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0733713d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Germany', 100),\n",
       " ('germany', 100),\n",
       " ('Netherland', 47),\n",
       " ('France', 46),\n",
       " ('Norway', 46),\n",
       " ('Urbana', 46),\n",
       " ('Ireland', 43),\n",
       " ('Malaysia', 40),\n",
       " (' New Zealand', 33),\n",
       " ('Italy', 33)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzywuzzy.process.extract(\"Germany\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14607706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "replace_matches_in_column(df=professors, column='Country', string_to_match=\"Germany\", min_ratio=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "091c1e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Australia', 'Austria']\n",
      "['Canada', 'China']\n",
      "['Finland', 'France']\n",
      "[' Germany', 'Greece', 'germany']\n",
      "['HongKong']\n",
      "['Ireland', 'Italy']\n",
      "['Japan']\n",
      "['Macau', 'Malaysia', 'Mauritius']\n",
      "[' New Zealand', 'Netherland', 'New Zealand', 'Norway']\n",
      "['Pakistan', 'Portugal']\n",
      "['Russian Federation']\n",
      "[' Sweden', 'Saudi Arabia', 'Scotland', 'Singapore', 'South Korea', 'SouthKorea', 'Spain', 'Sweden']\n",
      "['Thailand', 'Turkey']\n",
      "[' USA', 'UK', 'USA', 'USofA', 'Urbana']\n"
     ]
    }
   ],
   "source": [
    "listing('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b23482e",
   "metadata": {},
   "source": [
    "# Exercise - Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9a416",
   "metadata": {},
   "source": [
    "# Get our environment set up\n",
    "\n",
    "The first thing we'll need to do is load in the libraries and dataset we'll be using.  We use the same dataset from the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4eec88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helpful modules\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import chardet\n",
    "\n",
    "# read in all our data\n",
    "professors = pd.read_csv(\"../input/pakistan-intellectual-capital/pakistan_intellectual_capital.csv\")\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b686fdb",
   "metadata": {},
   "source": [
    "Next, we'll redo all of the work that we did in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c10253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# convert to lower case\n",
    "professors['Country'] = professors['Country'].str.lower()\n",
    "# remove trailing white spaces\n",
    "professors['Country'] = professors['Country'].str.strip()\n",
    "\n",
    "# get the top 10 closest matches to \"south korea\"\n",
    "countries = professors['Country'].unique()\n",
    "matches = fuzzywuzzy.process.extract(\"south korea\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "def replace_matches_in_column(df, column, string_to_match, min_ratio = 47):\n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    # get the top 10 closest matches to our input string\n",
    "    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n",
    "                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "    # only get matches with a ratio > 90\n",
    "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
    "\n",
    "    # get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match\n",
    "    \n",
    "    # let us know the function's done\n",
    "    print(\"All done!\")\n",
    "    \n",
    "replace_matches_in_column(df=professors, column='Country', string_to_match=\"south korea\")\n",
    "countries = professors['Country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb167880",
   "metadata": {},
   "source": [
    "### 1) Examine another column\n",
    "\n",
    "Write code below to take a look at all the unique values in the \"Graduated from\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9150812",
   "metadata": {},
   "outputs": [],
   "source": [
    "unis = professors['Graduated from'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f17f014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlisting(x, letters='abcdefghijklmnopqrstuvxyz'):\n",
    "    c = professors[x].unique()\n",
    "    c.sort()\n",
    "    for l in letters:\n",
    "        t = [x for x in c if re.search('^\\s*'+l, x, re.I)]\n",
    "        if t: print(t)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bbe44280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Columbia University', 'CECOS University of Information Technology and Emerging Sciences,Peshawar', 'COMSATS Institute of Information Technology', 'COMSATS Institute of Information Technology,Islamabad', 'COMSATS Institute of Information Technology,Lahore', 'COMSATS Institute of Information Technology,Vehari', 'COMSATS Institute of Information Technology,Wah Cantt', 'California State University', 'Capital University of Science & Technology', 'Capital University of Science and Technology', 'Carnegie Mellon University, Pittsburgh', 'Centre for Advanced Studies in Engineering', 'Chalmers University of Technology', 'Chinese Academy of Sciences', 'Chosun University', 'City University of Science and Technology', 'Colorado State University', 'Colorado Technical University', 'Columbia University', 'Concordia University,Montreal', 'Coventry University', 'Cranfield University']\n"
     ]
    }
   ],
   "source": [
    "xlisting('Graduated from', 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c38dc6",
   "metadata": {},
   "source": [
    "### 2) Do some text pre-processing\n",
    "Convert every entry in the \"Graduated from\" column in the professors DataFrame to remove white spaces at the beginning and end of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76974a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = professors['Country'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da0ca1",
   "metadata": {},
   "source": [
    "### 3) Continue working with countries\n",
    "In the tutorial, we focused on cleaning up inconsistencies in the \"Country\" column. Run the code cell below to view the list of unique values that we ended with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11f1c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['australia', 'austria']\n",
      "['canada', 'china']\n",
      "['finland', 'france']\n",
      "['germany', 'greece']\n",
      "['hongkong']\n",
      "['ireland', 'italy']\n",
      "['japan']\n",
      "['macau', 'malaysia', 'mauritius']\n",
      "['netherland', 'new zealand', 'norway']\n",
      "['pakistan', 'portugal']\n",
      "['russian federation']\n",
      "['saudi arabia', 'scotland', 'singapore', 'south korea', 'spain', 'sweden']\n",
      "['thailand', 'turkey']\n",
      "['uk', 'urbana', 'usa', 'usofa']\n"
     ]
    }
   ],
   "source": [
    "# get all the unique values in the 'City' column\n",
    "countries = professors['Country'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "countries.sort()\n",
    "listing('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13111e5",
   "metadata": {},
   "source": [
    "Take another look at the \"Country\" column and see if there's any more data cleaning we need to do.\n",
    "\n",
    "It looks like 'usa' and 'usofa' should be the same country. Correct the \"Country\" column in the dataframe so that 'usofa' appears instead as 'usa'.\n",
    "\n",
    "Use the most recent version of the DataFrame (with the whitespaces at the beginning and end of cells removed) from question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70d482ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "fuzzywuzzy.process.extract(\"usa\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "replace_matches_in_column(df=professors, column='Country', string_to_match=\"usa\", min_ratio=74)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5675d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
